import json
import logging
from abc import abstractmethod
from uuid import UUID

from aiohttp import ClientSession
from sentence_transformers import SentenceTransformer
from sqlalchemy import insert, select, update

from backend.src.core.enums import ActionStatus
from backend.src.engine.base_action import BaseAction
from config import LLM_API_KEY, LLM_BASE_URL, SCORE_SYSTEM_PROMPT
from core.models import CustomBaseModel
from db_models import Guidelines, MessagesEvaluations, ModeratorLogs, Moderators
from engine.models import MessageContext, MessageEvaluation
from utils.db import get_db_sess
from utils.llm import fetch_response, parse_to_json


class BaseModerator:
    _embedding_model: SentenceTransformer | None = None

    def __init__(
        self, moderator_id: UUID, logger: logging.Logger | None = None
    ) -> None:
        self._moderator_id = moderator_id
        self._logger = logger
        self._http_sess: ClientSession | None = None
        self._topics: list[str] | None = None
        self._guidelines: str | None = None

    @abstractmethod
    async def moderate(self) -> None: ...

    def _load_embedding_model(self) -> None:
        if self._embedding_model:
            return
        self._embedding_model = SentenceTransformer("Qwen/Qwen3-Embedding-0.6B")

    async def _fetch_llm_response(self, messages: list[dict]):
        data = await fetch_response(messages)
        content = data["choices"][0]["message"]["content"]
        self._logger.info(f"Content: {content}")
        return parse_to_json(content)

    async def _fetch_guidelines(self) -> tuple[str, list[str]]:
        async with get_db_sess() as db_sess:
            res = await db_sess.execute(
                select(Guidelines.text, Guidelines.topics).where(
                    Guidelines.guideline_id
                    == select(Moderators.guideline_id).where(
                        Moderators.moderator_id == self._moderator_id
                    )
                )
            )

            return res.first()

    async def _log_action(self, action: BaseAction) -> UUID:
        async with get_db_sess() as db_sess:
            res = await db_sess.scalar(
                insert(ModeratorLogs).values(
                    action_type=action.type,
                    params=action.to_serialisable_dict(),
                    status=(
                        ActionStatus.AWAITING_APPROVAL
                        if action.requires_approval
                        else ActionStatus.PENDING
                    ),
                )
                .returning(ModeratorLogs.log_id)
            )

            await db_sess.commit()
        
        return res
    
    async def _update_action_status(self, log_id: UUID, status: ActionStatus) -> None:
        async with get_db_sess() as db_sess:
            await db_sess.execute(update(ModeratorLogs).values(status=status.value).where(ModeratorLogs.log_id == log_id))
            await db_sess.commit()


    async def _save_evaluation(
        self, eval: MessageEvaluation, ctx: MessageContext
    ) -> None:
        """
        Stores the eval and generates embeddings for future
        similar retrieval.

        Args:
            eval (MessageEvaluation): Evaluation of the message.
            ctx (MessageContext): Context for the evaluation.
        """
        embedding = self._embedding_model.encode([ctx.content])[0]

        records = [
            {
                "moderator_id": self._moderator_id,
                "platform": ctx.platform.value,
                "content": ctx.content,
                "embedding": embedding,
                "topic": teval.topic,
                "topic_score": teval.topic_score,
            }
            for teval in eval.topic_evaluations
        ]

        if not records:
            return

        async with get_db_sess() as db_sess:
            await db_sess.execute(insert(MessagesEvaluations), records)
            await db_sess.commit()

    async def _fetch_topic_scores(self, ctx: MessageContext, topics: list[str]):
        sys_prompt = SCORE_SYSTEM_PROMPT.format(
            guidelines=self._guidelines, topics=topics
        )
        topic_scores: dict[str, float] = await self._fetch_llm_response(
            [
                {"role": "system", "content": sys_prompt},
                {
                    "role": "user",
                    "content": json.dumps(ctx.to_serialisable_dict()),
                },
            ]
        )
        return topic_scores

    async def _fetch_similar(self, text: str) -> tuple[tuple[str, float], ...]:
        embedding = self._embedding_model.encode([text])[0]
        async with get_db_sess() as db_sess:
            res = await db_sess.scalars(
                select(MessagesEvaluations).where(
                    MessagesEvaluations.embedding.l2_distance(embedding) < 0.5,
                    MessagesEvaluations.topic.in_(self._topics),
                )
            )

            return tuple((r.topic, r.topic_score) for r in res.yield_per(1000))

    async def _handle_similars(
        self, ctx: MessageContext, similars: tuple[tuple[str, float], ...]
    ) -> dict[str, float]:
        topic_scores = {}

        # TODO: Optimise
        for topic, score in similars:
            if topic in topic_scores:
                score, count = topic_scores[topic]
                score += score
                count += 1
                topic_scores[topic] = (round(score / count, 2), count)
            else:
                topic_scores[topic] = (score, 1)

        items = topic_scores.items()
        for k, (score, _) in items:
            topic_scores[k] = score

        remaining = set(self._topics).difference(set(topic_scores.keys()))
        if remaining:
            rem_scores = await self._fetch_topic_scores(ctx, list(remaining))
            for k, v in rem_scores:
                topic_scores[k] = v

        return topic_scores

    async def __aenter__(self):
        self._http_sess = ClientSession(
            base_url=LLM_BASE_URL, headers={"Authorization": f"Bearer {LLM_API_KEY}"}
        )
        return self

    async def __aexit__(self, exc_type, exc_value, tcb) -> None:
        await self._http_sess.close()
        self._http_sess = None
